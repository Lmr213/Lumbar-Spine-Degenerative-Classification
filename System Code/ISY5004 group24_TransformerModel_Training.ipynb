{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-31T01:12:56.040364Z",
     "iopub.status.busy": "2024-10-31T01:12:56.039510Z",
     "iopub.status.idle": "2024-10-31T01:13:19.469331Z",
     "shell.execute_reply": "2024-10-31T01:13:19.468366Z",
     "shell.execute_reply.started": "2024-10-31T01:12:56.040318Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n",
      "/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.20 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from pathlib import Path\n",
    "import timm\n",
    "import random\n",
    "from typing import List\n",
    "import glob\n",
    "\n",
    "from fastai.basics           import *\n",
    "from fastai.medical.imaging  import *\n",
    "\n",
    "from dataclasses import dataclass, field, asdict\n",
    "\n",
    "import logging\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T01:13:19.471731Z",
     "iopub.status.busy": "2024-10-31T01:13:19.471109Z",
     "iopub.status.idle": "2024-10-31T01:13:19.571473Z",
     "shell.execute_reply": "2024-10-31T01:13:19.570660Z",
     "shell.execute_reply.started": "2024-10-31T01:13:19.471697Z"
    }
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "@dataclass\n",
    "class DatasetConfig:\n",
    "    path: Path = Path('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/')\n",
    "    label_columns = [\n",
    "       'left_neural_foraminal_narrowing_l1_l2',\n",
    "       'left_neural_foraminal_narrowing_l2_l3',\n",
    "       'left_neural_foraminal_narrowing_l3_l4',\n",
    "       'left_neural_foraminal_narrowing_l4_l5',\n",
    "       'left_neural_foraminal_narrowing_l5_s1',\n",
    "       'right_neural_foraminal_narrowing_l1_l2',\n",
    "       'right_neural_foraminal_narrowing_l2_l3',\n",
    "       'right_neural_foraminal_narrowing_l3_l4',\n",
    "       'right_neural_foraminal_narrowing_l4_l5',\n",
    "       'right_neural_foraminal_narrowing_l5_s1']\n",
    "    label_map = {\n",
    "        'Normal/Mild': 0,\n",
    "        'Moderate': 1,\n",
    "        'Severe': 2,\n",
    "        -100: -100 # for missing values\n",
    "    }\n",
    "    use_n_images: int = 18  # select images\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    name: str = 'efficientnet_b3.ra2_in1k' # resnet or efficientnet\n",
    "    train_backbone: bool = False # fine-tuned?\n",
    "    use_weights: bool = True  # use weighted loss?\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    dataset: DatasetConfig = field(default_factory=DatasetConfig)\n",
    "    model: ModelConfig = field(default_factory=ModelConfig)\n",
    "    seed: int = 42\n",
    "    n_folds: int = 5\n",
    "        \n",
    "args = TrainingArguments(\n",
    "    output_dir='/kaggle/working/',\n",
    "    do_eval=True,\n",
    "    report_to='none',\n",
    "    remove_unused_columns=False,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=4,\n",
    "#     torch_compile=True,\n",
    "    num_train_epochs=5,\n",
    "    warmup_ratio=0.05,\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=10,\n",
    "   # save_strategy='epoch',\n",
    "    save_strategy='steps',\n",
    "    save_steps=2,\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    "    save_safetensors=False,\n",
    "#     fp16=True,\n",
    "    metric_for_best_model='log_loss',\n",
    "#    eval_strategy='epoch',\n",
    "    eval_strategy='steps',          # 设置为 'steps'，每隔一定batch评估一次\n",
    "    eval_steps=2,                  # 每10个 batch 评估一次\n",
    "    dataloader_num_workers=4,\n",
    "    label_names=['labels'],\n",
    "#     optim=\"adafactor\",\n",
    ")\n",
    "\n",
    "config = Config()\n",
    "\n",
    "wandb_config = {\n",
    "    'config': asdict(config),\n",
    "    'training_args': asdict(args)\n",
    "}\n",
    "\n",
    "import datetime\n",
    "NAME = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T01:13:19.572983Z",
     "iopub.status.busy": "2024-10-31T01:13:19.572671Z",
     "iopub.status.idle": "2024-10-31T01:13:20.849962Z",
     "shell.execute_reply": "2024-10-31T01:13:20.849062Z",
     "shell.execute_reply.started": "2024-10-31T01:13:19.572951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deddd34aa8e54a21aeea618ee71332fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config.model.name = 'resnet50'\n",
    "backbone = timm.create_model(config.model.name, pretrained=True)\n",
    "\n",
    "if not config.model.train_backbone:\n",
    "    for param in backbone.parameters():\n",
    "        param.require_grad = False\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(backbone)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "transforms.transforms[-1].mean = transforms.transforms[-1].mean.mean()\n",
    "transforms.transforms[-1].std = transforms.transforms[-1].std.mean()\n",
    "\n",
    "IMG_WIDTH, IMG_HEIGHT = transforms.transforms[1].size\n",
    "\n",
    "class Model1_ResNet(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super(Model1_ResNet, self).__init__()\n",
    "        self.name = \"ResNet\"\n",
    "        self.backbone = backbone\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.head = nn.Linear(self.backbone.num_features, len(config.dataset.label_columns)*3)\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        batch = dict(**kwargs)\n",
    "        # x: (B, N_IMAGES, C, H, W)\n",
    "        # \n",
    "        features_output = []\n",
    "        for series_description in ['Sagittal T2/STIR', 'Sagittal T1', 'Axial T2']:\n",
    "            if not series_description in batch:\n",
    "                # not used, we just forward zeros through backbone\n",
    "                features_output.append(None)\n",
    "            else:\n",
    "                images = batch[series_description]\n",
    "                # b 15 1 h w\n",
    "                B, N_IMAGES, C, H, W = images.shape\n",
    "                if config.model.train_backbone:\n",
    "                    features = self.backbone.forward_features(images.view(B * N_IMAGES, C, H, W))\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        features = self.backbone.forward_features(images.view(B * N_IMAGES, C, H, W))\n",
    "                features = self.pool(features).squeeze(-1).squeeze(-1)\n",
    "                features = self.head(features).view(B, N_IMAGES, -1)\n",
    "                # features: (B, N_IMAGES, label_columns * 3)\n",
    "                features_output.append(features)\n",
    "        for i in range(len(features_output)):\n",
    "            if features_output[i] is None:\n",
    "                features_output[i] = torch.zeros((B, N_IMAGES, self.backbone.num_features), device=images.device)\n",
    "        features_output = torch.cat(features_output, 1)\n",
    "        output = features_output.mean(1)\n",
    "        output = output.view(-1, 10, 3)\n",
    "\n",
    "        loss = None\n",
    "        if 'labels' in batch:\n",
    "            if config.model.use_weights:\n",
    "                loss_fn = torch.nn.CrossEntropyLoss(torch.tensor([1., 2., 4.], device=output.device))\n",
    "            else:\n",
    "                loss_fn = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(output.view(-1, 3), batch['labels'].view(-1, ))\n",
    "\n",
    "        return loss, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model efficient+lstm\n",
    "\n",
    "@todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T01:13:20.852878Z",
     "iopub.status.busy": "2024-10-31T01:13:20.852563Z",
     "iopub.status.idle": "2024-10-31T01:13:21.484711Z",
     "shell.execute_reply": "2024-10-31T01:13:21.483905Z",
     "shell.execute_reply.started": "2024-10-31T01:13:20.852846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db2ea81ca1314244a7e19fdb41f4ec39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/49.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config.model.name = 'efficientnet_b3.ra2_in1k'\n",
    "backbone = timm.create_model(config.model.name, pretrained=True)\n",
    "\n",
    "if not config.model.train_backbone:\n",
    "    for param in backbone.parameters():\n",
    "        param.require_grad = False\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(backbone)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "transforms.transforms[-1].mean = transforms.transforms[-1].mean.mean()\n",
    "transforms.transforms[-1].std = transforms.transforms[-1].std.mean()\n",
    "\n",
    "IMG_WIDTH, IMG_HEIGHT = transforms.transforms[1].size\n",
    "\n",
    "class Model2_LSTM(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super(Model2_LSTM, self).__init__()\n",
    "        self.name = \"LSTM\"\n",
    "        self.backbone = backbone\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.lstm = nn.LSTM(input_size=backbone.num_features * 3, hidden_size=512, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.head = nn.Linear(1024, len(config.dataset.label_columns)*3)\n",
    "\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        batch = dict(**kwargs)\n",
    "        # x: (B, N_IMAGES, C, H, W)\n",
    "        features_output = []\n",
    "        for series_description in ['Sagittal T2/STIR', 'Sagittal T1', 'Axial T2']:\n",
    "            if not series_description in batch:\n",
    "                # not used, we just forward zeros through backbone\n",
    "                features_output.append(None)\n",
    "            else:\n",
    "                images = batch[series_description]\n",
    "                B, N_IMAGES, C, H, W = images.shape\n",
    "                if config.model.train_backbone:\n",
    "                    features = self.backbone.forward_features(images.view(B * N_IMAGES, C, H, W))\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        features = self.backbone.forward_features(images.view(B * N_IMAGES, C, H, W))\n",
    "                features = self.pool(features).squeeze(-1).squeeze(-1).view(B, N_IMAGES, -1)\n",
    "                # features: (B, N_IMAGES, backbone.num_features)\n",
    "                features_output.append(features)\n",
    "        for i in range(len(features_output)):\n",
    "            if features_output[i] is None:\n",
    "                features_output[i] = torch.zeros((B, N_IMAGES, self.backbone.num_features), device=images.device)\n",
    "        features_output = torch.cat(features_output, -1)\n",
    "        lstm_out, _ = self.lstm(features_output)\n",
    "        # lstm_out: (B, N_IMAGES, 1024)\n",
    "        lstm_out = lstm_out.mean(1)\n",
    "        # lstm_out: (B, 1024)\n",
    "        output = self.head(lstm_out).view(-1, 10, 3)\n",
    "            \n",
    "        loss = None\n",
    "        if 'labels' in batch:\n",
    "            if config.model.use_weights:\n",
    "                loss_fn = torch.nn.CrossEntropyLoss(torch.tensor([1., 2., 4.], device=output.device))\n",
    "            else:\n",
    "                loss_fn = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(output.view(-1, 3), batch['labels'].view(-1, ))\n",
    "        \n",
    "        return loss, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model ResNet50 + Transformer\n",
    "\n",
    "@todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T01:13:21.486499Z",
     "iopub.status.busy": "2024-10-31T01:13:21.486058Z",
     "iopub.status.idle": "2024-10-31T01:13:22.050770Z",
     "shell.execute_reply": "2024-10-31T01:13:22.049833Z",
     "shell.execute_reply.started": "2024-10-31T01:13:21.486455Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "backbone = timm.create_model('resnet50', pretrained=True)\n",
    "if not config.model.train_backbone:\n",
    "    for param in backbone.parameters():\n",
    "        param.require_grad = False\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(backbone)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "transforms.transforms[-1].mean = transforms.transforms[-1].mean.mean()\n",
    "transforms.transforms[-1].std = transforms.transforms[-1].std.mean()\n",
    "\n",
    "IMG_WIDTH, IMG_HEIGHT = transforms.transforms[1].size\n",
    "\n",
    "class Model3_ViT(nn.Module):\n",
    "    def __init__(self, backbone = backbone,\n",
    "                 input_dim=2048, num_tokens=40, num_classes=30, d_model=512, nhead=8, num_layers=2):\n",
    "        super(Model3_ViT, self).__init__()\n",
    "        self.name = \"resNet50 + ViT\"\n",
    "        self.backbone = backbone\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.head = nn.Linear(1024, len(config.dataset.label_columns)*3)\n",
    "        \n",
    "        \n",
    "        # Linear layer to project input to the desired embedding dimension\n",
    "        self.input_projection = nn.Linear(input_dim, d_model)\n",
    "        # Positional encoding for the sequence length (num_tokens)\n",
    "        self.positional_encoding = nn.Parameter(torch.randn(1, num_tokens, d_model))\n",
    "        # Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        # Classification head\n",
    "        self.classifier = nn.Linear(d_model, num_classes)\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        batch = dict(**kwargs)\n",
    "        # x: (B, N_IMAGES, C, H, W)\n",
    "        features_output = []\n",
    "        for series_description in ['Sagittal T2/STIR', 'Sagittal T1', 'Axial T2']:\n",
    "            if not series_description in batch:\n",
    "                # not used, we just forward zeros through backbone\n",
    "                features_output.append(None)\n",
    "            else:\n",
    "                gray_images = batch[series_description].to('cuda')\n",
    "                images = gray_images.repeat(1, 1, 3, 1, 1)\n",
    "                \n",
    "                # Normalize images\n",
    "                mean = torch.tensor([0.485, 0.456, 0.406], device=images.device).view(1, 1, 3, 1, 1)\n",
    "                std = torch.tensor([0.229, 0.224, 0.225], device=images.device).view(1, 1, 3, 1, 1)\n",
    "                images = (images - mean) / std\n",
    "                \n",
    "                B, N_IMAGES, C, H, W = images.shape\n",
    "                if config.model.train_backbone:\n",
    "                    features = self.backbone.forward_features(images.view(B * N_IMAGES, C, H, W))\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        features = self.backbone.forward_features(images.view(B * N_IMAGES, C, H, W))\n",
    "                features = self.pool(features).squeeze(-1).squeeze(-1).view(B, N_IMAGES, -1)\n",
    "                \n",
    "                features_output.append(features)\n",
    "        for i in range(len(features_output)):\n",
    "            if features_output[i] is None:\n",
    "                features_output[i] = torch.zeros((B, N_IMAGES, self.backbone.num_features), device=images.device)\n",
    "        features_output = torch.cat(features_output, 1)\n",
    "        \n",
    "        \n",
    "        # Project input to d_model dimension\n",
    "        x = self.input_projection(features_output)  # Shape: (B, 40, d_model)\n",
    "        # Add positional encoding\n",
    "        x = x + self.positional_encoding  # Shape: (B, 40, d_model)\n",
    "        # Permute to (seq_len, batch, embedding_dim) for transformer\n",
    "        x = x.permute(1, 0, 2)  # Shape: (40, B, d_model)\n",
    "        # Transformer Encoder\n",
    "        x = self.transformer_encoder(x)  # Shape: (40, B, d_model)\n",
    "        # Take the mean of the sequence dimension for classification\n",
    "        x = x.mean(dim=0)  # Shape: (B, d_model\n",
    "        # Classification head\n",
    "        output = self.classifier(x)  # Shape: (B, num_classes)\n",
    "        \n",
    "#         output = self.classifier(features_output)\n",
    "        output = output.view(-1, 10, 3)\n",
    "            \n",
    "        loss = None\n",
    "        if 'labels' in batch:\n",
    "            if config.model.use_weights:\n",
    "                loss_fn = torch.nn.CrossEntropyLoss(torch.tensor([1., 2., 4.], device=output.device))\n",
    "            else:\n",
    "                loss_fn = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(output.view(-1, 3), batch['labels'].view(-1, ).to(\"cuda\"))\n",
    "        \n",
    "        return loss, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T01:13:22.052804Z",
     "iopub.status.busy": "2024-10-31T01:13:22.052247Z",
     "iopub.status.idle": "2024-10-31T01:13:23.339809Z",
     "shell.execute_reply": "2024-10-31T01:13:23.338942Z",
     "shell.execute_reply.started": "2024-10-31T01:13:22.052758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555b7ee1a1ff490986aa7d0a624dd207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30/1905565200.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(model_path))\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "model_path = \"/kaggle/input/resnet3/pytorch/default/1/resnet18_1_Input3Channels.pt\"\n",
    "import torch\n",
    "import timm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class Croper:\n",
    "    def __init__(self, model_path):\n",
    "#         self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.device = \"cpu\"\n",
    "        # Create ResNet18 model and set it to the device\n",
    "        self.model = timm.create_model('resnet18', pretrained=True, num_classes=10)\n",
    "        self.model.load_state_dict(torch.load(model_path))\n",
    "        self.model = self.model.to(self.device)   \n",
    "        self.model.eval()\n",
    "    \n",
    "\n",
    "    def crop_saggital(self, images, h, w):\n",
    "        results = []\n",
    "        for dicom_data in images:\n",
    "            image = dicom_data.pixel_array.astype(np.float32) # H, W\n",
    "            H, W = image.shape\n",
    "            img_tensor = torch.tensor(image).unsqueeze(0)\n",
    "\n",
    "            # Resize image to (1, 256, 256)\n",
    "            image_pre = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "            image_pre = torch.tensor(image_pre).unsqueeze(0)\n",
    "            image_pre = F.interpolate(image_pre.unsqueeze(0), size=(256, 256), mode='bilinear', align_corners=False).squeeze(0)  # (1, 256, 256)\n",
    "\n",
    "            # Change to (1, 3, 256, 256) by repeating the single channel 3 times\n",
    "            image_pre = image_pre.repeat(3, 1, 1).unsqueeze(0)  # (1, 3, 256, 256)\n",
    "\n",
    "            image_pre = image_pre.to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = self.model(image_pre)\n",
    "                output = torch.sigmoid(output)\n",
    "            output_np = output.cpu().numpy().flatten()\n",
    "            \n",
    "            x = output_np[0::2] * W\n",
    "            y = output_np[1::2] * H \n",
    "            points = np.stack([x, y], axis=1)\n",
    "\n",
    "            # 执行裁剪\n",
    "            for (px, py) in points:\n",
    "                x_start = max(px - w // 2, 0)\n",
    "                y_start = max(py - h // 2, 0)\n",
    "                crop = torch.zeros((1, h, w))\n",
    "                crop_region = img_tensor[:, int(y_start):int(min(y_start + h, H)), int(x_start):int(min(x_start + w, W))]\n",
    "                crop[:, :crop_region.shape[1], :crop_region.shape[2]] = crop_region\n",
    "                results.append(crop)\n",
    "            \n",
    "            #Debug\n",
    "            expected_size = torch.Size([1, 80, 150])\n",
    "            if crop.shape != expected_size:\n",
    "                print(crop.shape)\n",
    "                self.viz_kpts(image, points, h, w)\n",
    "\n",
    "#             self.viz_kpts(image, points, h, w)\n",
    "\n",
    "        # 堆叠结果并可视化裁剪后的图像\n",
    "        results = torch.stack(results)\n",
    "#         results = results.to('cuda')\n",
    "#         self.viz_crop_images(results)\n",
    "\n",
    "        return results\n",
    "    \n",
    "    def crop_axial(self, images, h, w):\n",
    "        results = [] \n",
    "\n",
    "        for dicom_data in images:\n",
    "            # Convert DICOM pixel data to float32\n",
    "            image = dicom_data.pixel_array.astype(np.float32)  # H, W\n",
    "            H, W = image.shape\n",
    "\n",
    "            # Convert to a tensor and add a channel dimension\n",
    "            img_tensor = torch.tensor(image).unsqueeze(0)  # (1, H, W)\n",
    "\n",
    "            # Calculate the center crop coordinates\n",
    "            center_h, center_w = H // 2, W // 2\n",
    "            start_h, end_h = max(0, center_h - h // 2), min(H, center_h + h // 2)\n",
    "            start_w, end_w = max(0, center_w - w // 2), min(W, center_w + w // 2)\n",
    "\n",
    "            # Crop the image to the desired height and width around the center\n",
    "            cropped_img = img_tensor[:, start_h:end_h, start_w:end_w]  # (1, h, w)\n",
    "\n",
    "            # Resize if necessary to ensure consistent shape\n",
    "            if cropped_img.shape[1] != h or cropped_img.shape[2] != w:\n",
    "                cropped_img = torch.nn.functional.interpolate(cropped_img.unsqueeze(0), size=(h, w), mode='bilinear', align_corners=False).squeeze(0)\n",
    "\n",
    "            results.append(cropped_img)\n",
    "\n",
    "        # If fewer than 10 images, fill the rest with zero tensors\n",
    "        while len(results) < 10:\n",
    "            results.append(torch.zeros(1, h, w, dtype=torch.float32))\n",
    "\n",
    "        # Stack results into a tensor of shape (10, 1, h, w)\n",
    "        results = torch.stack(results, dim=0)  # (10, 1, h, w)\n",
    "#         results = results.to('cuda')\n",
    "\n",
    "#         # Visualization of cropped images\n",
    "#         fig, axs = plt.subplots(1, 10, figsize=(15, 5))\n",
    "#         for i, cropped_img in enumerate(results):\n",
    "#             axs[i].imshow(cropped_img.squeeze(0), cmap='gray')\n",
    "#             axs[i].axis('off')\n",
    "#         plt.show()\n",
    "\n",
    "        return results\n",
    "\n",
    "    def viz_kpts(self, image, kpts, h, w):\n",
    "        \"\"\"\n",
    "        可视化关键点及裁剪框\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots(1)\n",
    "        ax.imshow(image, cmap=\"gray\")\n",
    "        \n",
    "        # 绘制关键点和裁剪框\n",
    "        for (x, y) in kpts:\n",
    "            ax.plot(x, y, 'ro')\n",
    "            rect = patches.Rectangle(\n",
    "                (x - w // 2, y - h // 2), w, h, linewidth=1, edgecolor='blue', facecolor='none'\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "    def viz_crop_images(self, images):\n",
    "        \"\"\"\n",
    "        批量可视化裁剪后的图像\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(1, len(images), figsize=(15, 5))\n",
    "        \n",
    "        for i, img in enumerate(images):\n",
    "            img_np = img.squeeze(0).cpu().numpy()\n",
    "            axes[i].imshow(img_np, cmap=\"gray\")\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "cropper1 = Croper(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data load\n",
    "- preprocess: data augmentation(todo) / train test split\n",
    "- data output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T01:13:23.341273Z",
     "iopub.status.busy": "2024-10-31T01:13:23.340966Z",
     "iopub.status.idle": "2024-10-31T01:13:23.436626Z",
     "shell.execute_reply": "2024-10-31T01:13:23.435910Z",
     "shell.execute_reply.started": "2024-10-31T01:13:23.341241Z"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ImagesDataset():\n",
    "    study_ids: List[int]\n",
    "    series_descriptions_df: pd.DataFrame\n",
    "    path: Path\n",
    "    is_train: bool\n",
    "    transforms: A.Compose | None = None\n",
    "    labels: pd.DataFrame | None = None\n",
    "        \n",
    "    def __post_init__(self):\n",
    "        if self.transforms is None:\n",
    "            self.transforms = lambda x: x\n",
    "        self.h_s = 80\n",
    "        self.w_s = 150\n",
    "        self.h_a = 160\n",
    "        self.w_a = 160\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.study_ids)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        study_id = self.study_ids[index]\n",
    "        \n",
    "        return_dict = {}\n",
    "\n",
    "        for series_description in ['Sagittal T2/STIR', 'Sagittal T1', 'Axial T2']:\n",
    "            rows = self.series_descriptions_df[\n",
    "                (self.series_descriptions_df.study_id == study_id)\n",
    "                & (self.series_descriptions_df.series_description == series_description)\n",
    "            ]\n",
    "\n",
    "            if len(rows) == 0:\n",
    "                if (series_description == 'Sagittal T2/STIR') or (series_description == 'Sagittal T1'):\n",
    "                    return_dict[series_description] = torch.zeros(15, 1, self.h_s, self.w_s)\n",
    "                elif (series_description == 'Axial T2'):\n",
    "                    return_dict[series_description] = torch.zeros(10, 1, self.h_a, self.w_a)\n",
    "            else:\n",
    "                \n",
    "                row = rows.iloc[0]\n",
    "                series_id = row.series_id\n",
    "                use_path = self.path / (\"train_images\" if self.is_train else \"test_images\") / f\"{study_id}/{series_id}\"\n",
    "                image_paths = sorted(glob.glob(str(use_path / \"*.dcm\")), key=lambda x: int(re.search(r\"(\\d+).dcm\", x).group(1)))\n",
    "                \n",
    "                if series_description in ['Sagittal T2/STIR', 'Sagittal T1']:\n",
    "                    center = len(image_paths) // 2\n",
    "                    indices = [center - 1, center, center + 1]\n",
    "                    image_paths = [image_paths[i] for i in indices]\n",
    "\n",
    "                    images = [Path(image_path).dcmread() for image_path in image_paths]\n",
    "                \n",
    "                    images = cropper1.crop_saggital(images, self.h_s, self.w_s)\n",
    "#                     print(images.shape)\n",
    "                    \n",
    "                elif (series_description == 'Axial T2'):\n",
    "                    num_images = len(image_paths)\n",
    "                    if num_images > 10:\n",
    "                        indices = [int(i * num_images / 10) for i in range(10)]\n",
    "                        selected_paths = [image_paths[i] for i in indices]\n",
    "                    else:\n",
    "                        selected_paths = image_paths  # If fewer than 10 images, select all\n",
    "                    images = [Path(image_path).dcmread() for image_path in selected_paths]\n",
    "                    images = cropper1.crop_axial(images, self.h_a, self.w_a)\n",
    "                    \n",
    "\n",
    "                return_dict[series_description] = images\n",
    "\n",
    "        if self.labels is not None:\n",
    "            return_dict['labels'] = torch.tensor(self.labels.iloc[index].values, dtype=torch.long)\n",
    "\n",
    "        return return_dict\n",
    "\n",
    "def load_data(path: Path):\n",
    "    sample_submission_df = pd.read_csv(path / 'sample_submission.csv')\n",
    "    sample_submission_df = sample_submission_df[sample_submission_df['row_id'].str.contains('neural_foraminal_narrowing')].reset_index(drop=True)\n",
    "\n",
    "    test_series_descriptions_df = pd.read_csv(path / 'test_series_descriptions.csv')\n",
    "    train_df = pd.read_csv(path / 'train.csv')\n",
    "    train_df = train_df[config.dataset.label_columns + ['study_id']].reset_index(drop=True)\n",
    "    train_series_descriptions_df = pd.read_csv(path / 'train_series_descriptions.csv')\n",
    "    \n",
    "    return sample_submission_df, test_series_descriptions_df, train_df, train_series_descriptions_df\n",
    "\n",
    "\n",
    "sample_submission_df, test_series_descriptions_df, train_df, train_series_descriptions_df = load_data(config.dataset.path)\n",
    "\n",
    "if DEBUG:\n",
    "    train_df = train_df.sample(100).reset_index(drop=True)\n",
    "\n",
    "# train_df, valid_df\n",
    "cv = GroupKFold(n_splits=config.n_folds)\n",
    "train_df['fold'] = -1\n",
    "\n",
    "for i, (train_idx, valid_idx) in enumerate(cv.split(train_df, groups=train_df['study_id'])):\n",
    "    train_df.loc[valid_idx, 'fold'] = i\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T01:13:23.438086Z",
     "iopub.status.busy": "2024-10-31T01:13:23.437711Z",
     "iopub.status.idle": "2024-10-31T01:13:24.248676Z",
     "shell.execute_reply": "2024-10-31T01:13:24.247736Z",
     "shell.execute_reply.started": "2024-10-31T01:13:23.438041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sagittal T2/STIR\n",
      "torch.Size([15, 1, 80, 150])\n",
      "Sagittal T1\n",
      "torch.Size([15, 1, 80, 150])\n",
      "Axial T2\n",
      "torch.Size([10, 1, 160, 160])\n",
      "labels\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "dataset = ImagesDataset(\n",
    "    study_ids=train_df.study_id.values.tolist(),\n",
    "    path=config.dataset.path,\n",
    "    is_train=True,\n",
    "    series_descriptions_df=train_series_descriptions_df,\n",
    "    transforms=transforms,\n",
    "    labels=train_df[config.dataset.label_columns].fillna(-100).apply(lambda xx: [config.dataset.label_map[x] for x in xx], raw=True)\n",
    ")\n",
    "\n",
    "index = dataset.study_ids.index(1028684462)\n",
    "data = dataset[index]\n",
    "for key in data:\n",
    "    print(key)\n",
    "    print(data[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T01:13:24.250303Z",
     "iopub.status.busy": "2024-10-31T01:13:24.249922Z",
     "iopub.status.idle": "2024-10-31T01:13:24.268705Z",
     "shell.execute_reply": "2024-10-31T01:13:24.267727Z",
     "shell.execute_reply.started": "2024-10-31T01:13:24.250267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>normal_mild</th>\n",
       "      <th>moderate</th>\n",
       "      <th>severe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44036939_left_neural_foraminal_narrowing_l1_l2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44036939_left_neural_foraminal_narrowing_l2_l3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44036939_left_neural_foraminal_narrowing_l3_l4</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44036939_left_neural_foraminal_narrowing_l4_l5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44036939_left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44036939_right_neural_foraminal_narrowing_l1_l2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44036939_right_neural_foraminal_narrowing_l2_l3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44036939_right_neural_foraminal_narrowing_l3_l4</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>44036939_right_neural_foraminal_narrowing_l4_l5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44036939_right_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            row_id  normal_mild  moderate  \\\n",
       "0   44036939_left_neural_foraminal_narrowing_l1_l2     0.333333  0.333333   \n",
       "1   44036939_left_neural_foraminal_narrowing_l2_l3     0.333333  0.333333   \n",
       "2   44036939_left_neural_foraminal_narrowing_l3_l4     0.333333  0.333333   \n",
       "3   44036939_left_neural_foraminal_narrowing_l4_l5     0.333333  0.333333   \n",
       "4   44036939_left_neural_foraminal_narrowing_l5_s1     0.333333  0.333333   \n",
       "5  44036939_right_neural_foraminal_narrowing_l1_l2     0.333333  0.333333   \n",
       "6  44036939_right_neural_foraminal_narrowing_l2_l3     0.333333  0.333333   \n",
       "7  44036939_right_neural_foraminal_narrowing_l3_l4     0.333333  0.333333   \n",
       "8  44036939_right_neural_foraminal_narrowing_l4_l5     0.333333  0.333333   \n",
       "9  44036939_right_neural_foraminal_narrowing_l5_s1     0.333333  0.333333   \n",
       "\n",
       "     severe  \n",
       "0  0.333333  \n",
       "1  0.333333  \n",
       "2  0.333333  \n",
       "3  0.333333  \n",
       "4  0.333333  \n",
       "5  0.333333  \n",
       "6  0.333333  \n",
       "7  0.333333  \n",
       "8  0.333333  \n",
       "9  0.333333  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T01:13:24.272404Z",
     "iopub.status.busy": "2024-10-31T01:13:24.271787Z",
     "iopub.status.idle": "2024-10-31T01:13:24.281795Z",
     "shell.execute_reply": "2024-10-31T01:13:24.280796Z",
     "shell.execute_reply.started": "2024-10-31T01:13:24.272366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>series_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44036939</td>\n",
       "      <td>2828203845</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44036939</td>\n",
       "      <td>3481971518</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44036939</td>\n",
       "      <td>3844393089</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id   series_id series_description\n",
       "0  44036939  2828203845        Sagittal T1\n",
       "1  44036939  3481971518           Axial T2\n",
       "2  44036939  3844393089   Sagittal T2/STIR"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_series_descriptions_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T01:13:24.283121Z",
     "iopub.status.busy": "2024-10-31T01:13:24.282805Z",
     "iopub.status.idle": "2024-10-31T01:13:24.301892Z",
     "shell.execute_reply": "2024-10-31T01:13:24.300965Z",
     "shell.execute_reply.started": "2024-10-31T01:13:24.283087Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_neural_foraminal_narrowing_l1_l2</th>\n",
       "      <th>left_neural_foraminal_narrowing_l2_l3</th>\n",
       "      <th>left_neural_foraminal_narrowing_l3_l4</th>\n",
       "      <th>left_neural_foraminal_narrowing_l4_l5</th>\n",
       "      <th>left_neural_foraminal_narrowing_l5_s1</th>\n",
       "      <th>right_neural_foraminal_narrowing_l1_l2</th>\n",
       "      <th>right_neural_foraminal_narrowing_l2_l3</th>\n",
       "      <th>right_neural_foraminal_narrowing_l3_l4</th>\n",
       "      <th>right_neural_foraminal_narrowing_l4_l5</th>\n",
       "      <th>right_neural_foraminal_narrowing_l5_s1</th>\n",
       "      <th>study_id</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>4003253</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>4646740</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>7143189</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>8785691</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>10728036</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>11340341</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>11943292</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>13317052</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>22191399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>26342422</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  left_neural_foraminal_narrowing_l1_l2 left_neural_foraminal_narrowing_l2_l3  \\\n",
       "0                           Normal/Mild                           Normal/Mild   \n",
       "1                           Normal/Mild                           Normal/Mild   \n",
       "2                           Normal/Mild                           Normal/Mild   \n",
       "3                           Normal/Mild                           Normal/Mild   \n",
       "4                           Normal/Mild                           Normal/Mild   \n",
       "5                           Normal/Mild                           Normal/Mild   \n",
       "6                           Normal/Mild                           Normal/Mild   \n",
       "7                           Normal/Mild                           Normal/Mild   \n",
       "8                           Normal/Mild                           Normal/Mild   \n",
       "9                           Normal/Mild                           Normal/Mild   \n",
       "\n",
       "  left_neural_foraminal_narrowing_l3_l4 left_neural_foraminal_narrowing_l4_l5  \\\n",
       "0                           Normal/Mild                              Moderate   \n",
       "1                           Normal/Mild                              Moderate   \n",
       "2                           Normal/Mild                           Normal/Mild   \n",
       "3                           Normal/Mild                              Moderate   \n",
       "4                           Normal/Mild                           Normal/Mild   \n",
       "5                           Normal/Mild                           Normal/Mild   \n",
       "6                           Normal/Mild                           Normal/Mild   \n",
       "7                           Normal/Mild                              Moderate   \n",
       "8                           Normal/Mild                           Normal/Mild   \n",
       "9                           Normal/Mild                           Normal/Mild   \n",
       "\n",
       "  left_neural_foraminal_narrowing_l5_s1  \\\n",
       "0                           Normal/Mild   \n",
       "1                              Moderate   \n",
       "2                           Normal/Mild   \n",
       "3                              Moderate   \n",
       "4                           Normal/Mild   \n",
       "5                           Normal/Mild   \n",
       "6                           Normal/Mild   \n",
       "7                                Severe   \n",
       "8                           Normal/Mild   \n",
       "9                           Normal/Mild   \n",
       "\n",
       "  right_neural_foraminal_narrowing_l1_l2  \\\n",
       "0                            Normal/Mild   \n",
       "1                            Normal/Mild   \n",
       "2                            Normal/Mild   \n",
       "3                            Normal/Mild   \n",
       "4                            Normal/Mild   \n",
       "5                            Normal/Mild   \n",
       "6                            Normal/Mild   \n",
       "7                            Normal/Mild   \n",
       "8                            Normal/Mild   \n",
       "9                            Normal/Mild   \n",
       "\n",
       "  right_neural_foraminal_narrowing_l2_l3  \\\n",
       "0                            Normal/Mild   \n",
       "1                            Normal/Mild   \n",
       "2                            Normal/Mild   \n",
       "3                            Normal/Mild   \n",
       "4                            Normal/Mild   \n",
       "5                            Normal/Mild   \n",
       "6                            Normal/Mild   \n",
       "7                            Normal/Mild   \n",
       "8                            Normal/Mild   \n",
       "9                            Normal/Mild   \n",
       "\n",
       "  right_neural_foraminal_narrowing_l3_l4  \\\n",
       "0                               Moderate   \n",
       "1                               Moderate   \n",
       "2                            Normal/Mild   \n",
       "3                            Normal/Mild   \n",
       "4                            Normal/Mild   \n",
       "5                            Normal/Mild   \n",
       "6                            Normal/Mild   \n",
       "7                               Moderate   \n",
       "8                            Normal/Mild   \n",
       "9                            Normal/Mild   \n",
       "\n",
       "  right_neural_foraminal_narrowing_l4_l5  \\\n",
       "0                               Moderate   \n",
       "1                               Moderate   \n",
       "2                            Normal/Mild   \n",
       "3                            Normal/Mild   \n",
       "4                            Normal/Mild   \n",
       "5                               Moderate   \n",
       "6                            Normal/Mild   \n",
       "7                               Moderate   \n",
       "8                               Moderate   \n",
       "9                            Normal/Mild   \n",
       "\n",
       "  right_neural_foraminal_narrowing_l5_s1  study_id  fold  \n",
       "0                            Normal/Mild   4003253     0  \n",
       "1                            Normal/Mild   4646740     2  \n",
       "2                            Normal/Mild   7143189     1  \n",
       "3                            Normal/Mild   8785691     0  \n",
       "4                            Normal/Mild  10728036     4  \n",
       "5                            Normal/Mild  11340341     3  \n",
       "6                            Normal/Mild  11943292     2  \n",
       "7                            Normal/Mild  13317052     1  \n",
       "8                               Moderate  22191399     1  \n",
       "9                            Normal/Mild  26342422     0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T01:13:24.303529Z",
     "iopub.status.busy": "2024-10-31T01:13:24.303242Z",
     "iopub.status.idle": "2024-10-31T01:13:24.315650Z",
     "shell.execute_reply": "2024-10-31T01:13:24.314650Z",
     "shell.execute_reply.started": "2024-10-31T01:13:24.303487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>series_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4003253</td>\n",
       "      <td>1054713880</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4003253</td>\n",
       "      <td>2448190387</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4646740</td>\n",
       "      <td>3201256954</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4646740</td>\n",
       "      <td>3486248476</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4646740</td>\n",
       "      <td>3666319702</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7143189</td>\n",
       "      <td>132939515</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7143189</td>\n",
       "      <td>1951927562</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7143189</td>\n",
       "      <td>3219733239</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8785691</td>\n",
       "      <td>481125819</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_id   series_id series_description\n",
       "0   4003253   702807833   Sagittal T2/STIR\n",
       "1   4003253  1054713880        Sagittal T1\n",
       "2   4003253  2448190387           Axial T2\n",
       "3   4646740  3201256954           Axial T2\n",
       "4   4646740  3486248476        Sagittal T1\n",
       "5   4646740  3666319702   Sagittal T2/STIR\n",
       "6   7143189   132939515   Sagittal T2/STIR\n",
       "7   7143189  1951927562           Axial T2\n",
       "8   7143189  3219733239        Sagittal T1\n",
       "9   8785691   481125819   Sagittal T2/STIR"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_series_descriptions_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T01:13:24.317643Z",
     "iopub.status.busy": "2024-10-31T01:13:24.317284Z",
     "iopub.status.idle": "2024-10-31T01:13:24.346288Z",
     "shell.execute_reply": "2024-10-31T01:13:24.345453Z",
     "shell.execute_reply.started": "2024-10-31T01:13:24.317608Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def build_gt_submission_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    " \n",
    "    df = df.drop('fold', axis=1).set_index('study_id').T\n",
    "    rows = itertools.product(df.columns, df.index)\n",
    "    values = df.values.flatten()\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        'row_id': [f'{study_id}_{location}' for study_id, location in rows],\n",
    "        'normal_mild': [1 if value == 'Normal/Mild' else 0 for value in values],\n",
    "        'moderate': [1 if value == 'Moderate' else 0 for value in values],\n",
    "        'severe': [1 if value == 'Severe' else 0 for value in values],\n",
    "    })\n",
    "    \n",
    "    result_df.loc[\n",
    "        (result_df['normal_mild'] == 0)\n",
    "        & (result_df['moderate'] == 0)\n",
    "        & (result_df['severe'] == 0),\n",
    "        'normal_mild'\n",
    "    ] = 1\n",
    "    \n",
    "    return result_df\n",
    "    \n",
    "def prepare_dataset(df, series_descriptions_df, config, is_train=True):\n",
    "    dataset = ImagesDataset(\n",
    "        study_ids=df.study_id.values.tolist(),\n",
    "        path=config.dataset.path,\n",
    "        is_train=is_train,\n",
    "        series_descriptions_df=series_descriptions_df,\n",
    "        transforms=transforms,\n",
    "        labels=df[config.dataset.label_columns].fillna(-100).apply(lambda xx: [config.dataset.label_map[x] for x in xx], raw=True)\n",
    "    )\n",
    "    gt_submission = build_gt_submission_df(df)\n",
    "    gt_submission['sample_weight'] = gt_submission.apply(lambda row: row['normal_mild'] + row['moderate'] * 2 + row['severe'] * 4, axis=1)\n",
    "    return dataset, gt_submission\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_condition(full_location: str) -> str:\n",
    "    # Given an input like spinal_canal_stenosis_l1_l2 extracts 'spinal'\n",
    "    for injury_condition in ['spinal', 'foraminal', 'subarticular']:\n",
    "        if injury_condition in full_location:\n",
    "            return injury_condition\n",
    "    raise ValueError(f'condition not found in {full_location}')\n",
    "\n",
    "\n",
    "def score(\n",
    "        solution: pd.DataFrame,\n",
    "        submission: pd.DataFrame,\n",
    "        row_id_column_name: str,\n",
    "        any_severe_scalar: float\n",
    "    ) -> float:\n",
    "    '''\n",
    "    Pseudocode:\n",
    "    1. Calculate the sample weighted log loss for each medical condition:\n",
    "    2. Derive a new any_severe label.\n",
    "    3. Calculate the sample weighted log loss for the new any_severe label.\n",
    "    4. Return the average of all of the label group log losses as the final score, normalized for the number of columns in each group.\n",
    "       This mitigates the impact of spinal stenosis having only half as many columns as the other two conditions.\n",
    "    '''\n",
    "\n",
    "    target_levels = ['normal_mild', 'moderate', 'severe']\n",
    "\n",
    "    # Run basic QC checks on the inputs\n",
    "    if not pd.api.types.is_numeric_dtype(submission[target_levels].values):\n",
    "        raise ParticipantVisibleError('All submission values must be numeric')\n",
    "\n",
    "    if not np.isfinite(submission[target_levels].values).all():\n",
    "        raise ParticipantVisibleError('All submission values must be finite')\n",
    "\n",
    "    if solution[target_levels].min().min() < 0:\n",
    "        raise ParticipantVisibleError('All labels must be at least zero')\n",
    "    if submission[target_levels].min().min() < 0:\n",
    "        raise ParticipantVisibleError('All predictions must be at least zero')\n",
    "\n",
    "    solution['study_id'] = solution['row_id'].apply(lambda x: x.split('_')[0])\n",
    "    solution['location'] = solution['row_id'].apply(lambda x: '_'.join(x.split('_')[1:]))\n",
    "    solution['condition'] = solution['row_id'].apply(get_condition)\n",
    "\n",
    "    del solution[row_id_column_name]\n",
    "    del submission[row_id_column_name]\n",
    "    assert sorted(submission.columns) == sorted(target_levels)\n",
    "\n",
    "    submission['study_id'] = solution['study_id']\n",
    "    submission['location'] = solution['location']\n",
    "    submission['condition'] = solution['condition']\n",
    "\n",
    "    condition_losses = []\n",
    "    condition_weights = []\n",
    "    for condition in ['foraminal']:\n",
    "        condition_indices = solution.loc[solution['condition'] == condition].index.values\n",
    "        condition_loss = sklearn.metrics.log_loss(\n",
    "            y_true=solution.loc[condition_indices, target_levels].values,\n",
    "            y_pred=submission.loc[condition_indices, target_levels].values,\n",
    "            sample_weight=solution.loc[condition_indices, 'sample_weight'].values\n",
    "        )\n",
    "        condition_losses.append(condition_loss)\n",
    "        condition_weights.append(1)\n",
    "\n",
    "    return np.average(condition_losses, weights=condition_weights)\n",
    "\n",
    "# 这段代码是不是不对？\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x, 2, keepdims=True))\n",
    "    return e_x / e_x.sum(2, keepdims=True)\n",
    "\n",
    "# eval_pred - 预测结果(Nx10x3) valid_gt_submission - 真值\n",
    "def compute_metrics(eval_pred, valid_gt_submission):\n",
    "    logits, _ = eval_pred \n",
    "#     print(logits[0:10, :, :])\n",
    "    logits = softmax(logits)\n",
    "#     print(logits[0:10, :, :])\n",
    "\n",
    "    # 将预测结果展开到表格中\n",
    "    submission_df = pd.DataFrame({\n",
    "        'row_id': valid_gt_submission['row_id'].values.tolist(),\n",
    "        'normal_mild': logits[:, :, 0].flatten(),\n",
    "        'moderate': logits[:, :, 1].flatten(),\n",
    "        'severe': logits[:, :, 2].flatten(),\n",
    "    })\n",
    "\n",
    "#     print(valid_gt_submission.head(10))\n",
    "#     print(submission_df.head(10))\n",
    "\n",
    "    # 计算返回valid_loss\n",
    "    return {\n",
    "        'log_loss': score(valid_gt_submission.copy(), submission_df.copy(), 'row_id', 1.0)\n",
    "    }\n",
    "\n",
    "def train_fold(fold, train_df, train_series_descriptions_df, config, args):\n",
    "    \n",
    "    # 根据fold划分train和valid(方便进行 cross-validation,选择某个fold的数据作为valid)\n",
    "    fold_train_df = train_df[train_df.fold != fold].reset_index(drop=True)\n",
    "    fold_valid_df = train_df[train_df.fold == fold].reset_index(drop=True)\n",
    "\n",
    "    fold_train_series_descriptions_df = train_series_descriptions_df[train_series_descriptions_df.study_id.isin(fold_train_df.study_id)]\n",
    "    fold_valid_series_descriptions_df = train_series_descriptions_df[train_series_descriptions_df.study_id.isin(fold_valid_df.study_id)]\n",
    "\n",
    "    train_dataset, _ = prepare_dataset(fold_train_df, fold_train_series_descriptions_df, config)\n",
    "    valid_dataset, valid_gt_submission = prepare_dataset(fold_valid_df, fold_valid_series_descriptions_df, config)\n",
    "\n",
    "    model = Model3_ViT(backbone) # can change to diffrent model\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args=args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        compute_metrics=lambda eval_pred: compute_metrics(eval_pred, valid_gt_submission),\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    \n",
    "    torch.save(model.state_dict(), f\"best_model_{model.name}_fold_{fold}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T01:13:24.347645Z",
     "iopub.status.busy": "2024-10-31T01:13:24.347310Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 61/250 1:08:40 < 3:40:00, 0.01 it/s, Epoch 1.20/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Log Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "      <th>Steps Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.109499</td>\n",
       "      <td>1.110000</td>\n",
       "      <td>200.324600</td>\n",
       "      <td>1.972000</td>\n",
       "      <td>0.494000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.077113</td>\n",
       "      <td>1.088050</td>\n",
       "      <td>161.672400</td>\n",
       "      <td>2.443000</td>\n",
       "      <td>0.612000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.021924</td>\n",
       "      <td>1.049534</td>\n",
       "      <td>163.176700</td>\n",
       "      <td>2.421000</td>\n",
       "      <td>0.607000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.956432</td>\n",
       "      <td>1.009194</td>\n",
       "      <td>161.048800</td>\n",
       "      <td>2.453000</td>\n",
       "      <td>0.615000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.039000</td>\n",
       "      <td>0.894337</td>\n",
       "      <td>0.983785</td>\n",
       "      <td>140.602400</td>\n",
       "      <td>2.809000</td>\n",
       "      <td>0.704000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.039000</td>\n",
       "      <td>0.848975</td>\n",
       "      <td>0.988502</td>\n",
       "      <td>132.866600</td>\n",
       "      <td>2.973000</td>\n",
       "      <td>0.745000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.039000</td>\n",
       "      <td>0.823512</td>\n",
       "      <td>1.022271</td>\n",
       "      <td>131.907400</td>\n",
       "      <td>2.995000</td>\n",
       "      <td>0.751000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.039000</td>\n",
       "      <td>0.809263</td>\n",
       "      <td>1.067815</td>\n",
       "      <td>133.635800</td>\n",
       "      <td>2.956000</td>\n",
       "      <td>0.741000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.039000</td>\n",
       "      <td>0.800574</td>\n",
       "      <td>1.107722</td>\n",
       "      <td>135.383000</td>\n",
       "      <td>2.918000</td>\n",
       "      <td>0.731000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.843400</td>\n",
       "      <td>0.796279</td>\n",
       "      <td>1.141306</td>\n",
       "      <td>135.063400</td>\n",
       "      <td>2.925000</td>\n",
       "      <td>0.733000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.843400</td>\n",
       "      <td>0.793483</td>\n",
       "      <td>1.164181</td>\n",
       "      <td>135.287500</td>\n",
       "      <td>2.920000</td>\n",
       "      <td>0.732000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.843400</td>\n",
       "      <td>0.790574</td>\n",
       "      <td>1.169833</td>\n",
       "      <td>136.200800</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>0.727000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.843400</td>\n",
       "      <td>0.790556</td>\n",
       "      <td>1.172154</td>\n",
       "      <td>136.949200</td>\n",
       "      <td>2.884000</td>\n",
       "      <td>0.723000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.843400</td>\n",
       "      <td>0.793608</td>\n",
       "      <td>1.176888</td>\n",
       "      <td>135.886000</td>\n",
       "      <td>2.907000</td>\n",
       "      <td>0.729000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.843200</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>1.177274</td>\n",
       "      <td>136.565100</td>\n",
       "      <td>2.892000</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.843200</td>\n",
       "      <td>0.796731</td>\n",
       "      <td>1.171414</td>\n",
       "      <td>132.823700</td>\n",
       "      <td>2.974000</td>\n",
       "      <td>0.745000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.843200</td>\n",
       "      <td>0.796315</td>\n",
       "      <td>1.165476</td>\n",
       "      <td>138.541000</td>\n",
       "      <td>2.851000</td>\n",
       "      <td>0.715000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.843200</td>\n",
       "      <td>0.796628</td>\n",
       "      <td>1.160199</td>\n",
       "      <td>134.374600</td>\n",
       "      <td>2.940000</td>\n",
       "      <td>0.737000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.843200</td>\n",
       "      <td>0.797022</td>\n",
       "      <td>1.154500</td>\n",
       "      <td>133.132200</td>\n",
       "      <td>2.967000</td>\n",
       "      <td>0.744000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.847200</td>\n",
       "      <td>0.798409</td>\n",
       "      <td>1.149613</td>\n",
       "      <td>134.478200</td>\n",
       "      <td>2.937000</td>\n",
       "      <td>0.736000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.847200</td>\n",
       "      <td>0.799033</td>\n",
       "      <td>1.147256</td>\n",
       "      <td>119.416800</td>\n",
       "      <td>3.308000</td>\n",
       "      <td>0.829000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.847200</td>\n",
       "      <td>0.796299</td>\n",
       "      <td>1.142735</td>\n",
       "      <td>118.223600</td>\n",
       "      <td>3.341000</td>\n",
       "      <td>0.837000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.847200</td>\n",
       "      <td>0.793789</td>\n",
       "      <td>1.134139</td>\n",
       "      <td>116.696800</td>\n",
       "      <td>3.385000</td>\n",
       "      <td>0.848000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.847200</td>\n",
       "      <td>0.792549</td>\n",
       "      <td>1.122301</td>\n",
       "      <td>117.794200</td>\n",
       "      <td>3.353000</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.808100</td>\n",
       "      <td>0.792747</td>\n",
       "      <td>1.116146</td>\n",
       "      <td>119.293800</td>\n",
       "      <td>3.311000</td>\n",
       "      <td>0.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.808100</td>\n",
       "      <td>0.795286</td>\n",
       "      <td>1.116531</td>\n",
       "      <td>178.786200</td>\n",
       "      <td>2.209000</td>\n",
       "      <td>0.554000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.808100</td>\n",
       "      <td>0.799864</td>\n",
       "      <td>1.118612</td>\n",
       "      <td>136.822600</td>\n",
       "      <td>2.887000</td>\n",
       "      <td>0.724000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.808100</td>\n",
       "      <td>0.804227</td>\n",
       "      <td>1.122015</td>\n",
       "      <td>135.774100</td>\n",
       "      <td>2.909000</td>\n",
       "      <td>0.729000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.808100</td>\n",
       "      <td>0.804630</td>\n",
       "      <td>1.126536</td>\n",
       "      <td>136.573400</td>\n",
       "      <td>2.892000</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='99' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/99 01:09 < 01:18, 0.67 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    }
   ],
   "source": [
    "for fold in range(1):\n",
    "    train_fold(fold, train_df, train_series_descriptions_df, config, args) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8561470,
     "sourceId": 71549,
     "sourceType": "competition"
    },
    {
     "modelId": 148270,
     "modelInstanceId": 125286,
     "sourceId": 147649,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 149117,
     "modelInstanceId": 126145,
     "sourceId": 148649,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 151400,
     "modelInstanceId": 128526,
     "sourceId": 151353,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 151404,
     "modelInstanceId": 128530,
     "sourceId": 151357,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
